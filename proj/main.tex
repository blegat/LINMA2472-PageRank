\documentclass{article}

\usepackage[utf8x]{inputenc}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{fullpage}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{todonotes}

% Math symbols
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}

% Numbers and units
\usepackage{siunitx}

\DeclareMathOperator{\newdiff}{d} % use \dif instead
\newcommand{\dif}{\newdiff\!}
\newcommand{\fpart}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\ffpart}[2]{\frac{\partial^2 #1}{\partial #2^2}}
\newcommand{\fdpart}[3]{\frac{\partial^2 #1}{\partial #2\partial #3}}
\newcommand{\fdif}[2]{\frac{\dif #1}{\dif #2}}
\newcommand{\ffdif}[2]{\frac{\dif^2 #1}{\dif #2^2}}
\newcommand{\constant}{\ensuremath{\mathrm{cst}}}
\newcommand{\bigoh}{\mathcal{O}}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\newcommand{\1}{\mathbf{1}}

% Theorem and definitions
\theoremstyle{definition}
\newtheorem{mydef}{Définition}
\newtheorem{mynota}[mydef]{Notation}
\newtheorem{myprop}[mydef]{Propriétés}
\newtheorem{myrem}[mydef]{Remarque}
\newtheorem{myform}[mydef]{Formules}
\newtheorem{mycorr}[mydef]{Corrolaire}
\newtheorem{mytheo}[mydef]{Théorème}
\newtheorem{mylem}[mydef]{Lemme}
\newtheorem{myexem}[mydef]{Exemple}
\newtheorem{myineg}[mydef]{Inégalité}



\author{Benoît Legat \and Quentin Laurent}
\title{PageRank optimization}

\begin{document}

\maketitle

\section{Reminder}
We will adopt the transposed notation due to the fact that all papers do so.

So
\[ \pi_{k+1}^T = \pi_k^T cP + t^T(1-c) \]
or
\[ \pi_{k+1}^T = \pi_k^T (cP + \1 t^T(1-c)) \]
and at the convergence
\[ \pi^T = \pi^T (cP + \1 t^T(1-c)) \]
so
\[ \pi^T = (1-c)\1 t^T(I - cP)^{-1} \]
where $(1 - cP)^{-1} \triangleq Z$ as we will see later.

\section{Optimal link structures for various cases}
In \cite{de2008maximizing} it is demonstrated that the pagerank of a set of pages which maximizes the pagerank of a set $\mathcal{P}$, denoted $\pi^T e_{P}$ has a particular structure.\\
\begin{mytheo}
It is stated that for $\mathcal{E}_{in}$, $\mathcal{E}_{\overline{\mathcal{P}}}$ given, if  $\pi^T e_{P}$ is maximal under assumption A, then there exists a permutation of the indices such that 
$\mathcal{P} = \{1,2, \hdots, n_{\mathcal{P}}\}$,
$$ v_1 > ... > v_{n_P}>v_{n_{\mathcal{P}}}+1 \geq ... \geq v_n$$
and $\mathcal{E}_{\mathcal{P}}$ and $\mathcal{E}_{out(\mathcal{P})} $ have the following structure :
$$\mathcal{E}_{\mathcal{P}} = \{(i,j) \in \mathcal{P}\times \mathcal{P} : j \leq i or j = i+1 \}$$
$$\mathcal{E}_{out(\mathcal{P})} = \{(n_{\mathcal{P}},n_{\mathcal{P}}+1)\}$$
\label{thm:optstruct}
\end{mytheo}
\subsection{Maximizing the pagerank of a target set}
It might be more useful to maximize the pagerank of a single page since a single page with a very high pagerank is more likely to appear high on the ordering of a search engine than a set of pages with moderately high pagerank. More generally we might want to consider maximizing the pagerank of a target subset $\mathcal{T} \subset \mathcal{P}$($\mathcal{P}$ is still the set whose outlinks we control).
We can see that theorem \ref{thm:optstruct} still holds for the links of $\mathcal{E}_{\mathcal{T}}$ and of $\mathcal{E}_{out(\mathcal{T})}$, but we cannot generalize so easily to the links of $\mathcal{E}_{\mathcal{P}\setminus \mathcal{T}}$
%TODO : examples

\subsection{Maximizing the pagerank without self-links}
In this case the optimal structure is simply modified by substracting the self links of the optimal structure described in theorem \ref{thm:optstruct}. The theorem 11 and 12 of \cite{de2008maximizing} generalize very easily in this case.
%TODO : Try to quantify the difference in pagerank in this case.
\subsection{Controlled set is a singleton}
In the case of a single node, since we know that $\mathcal{V} = \mathcal{V}_0$, we have that $\mathcal{E}_{out(\mathcal{P})} \subset (i,j) \: s.t. \: j \in \mathcal{V}_0$
\subsection{Optimal structure with several external outlinks}


\subsection{Target set is a singleton}


\section{The effect of adding links}
\cite{avrachenkov2004decomposition} show that adding a link
from $i$ to $j$ always increase the PageRank of $j$.
The worst case for a page is having no inlinks which gives a PageRank of $(1-c)/n$.

It analyses the decomposition of the web in communities,
set of pages that does not link to each other (because they are of a difference subject for example).
This is excellent for parallelizing the computation of PageRank.
He then proves that a community has no interest in adding link to another community,
in will decrease its PageRank.

This is an example that show that adding an outlink for a page $p$ can decrease the PageRank of $p$.
However, it can also increase the PageRank of a page.
Consider for example the case where $p$ links to a page of another community.
Adding a link from $p$ to a page that links to $p$ can decrease the number of random surfers that go to this other community and increase the PageRank of $p$.

This gives the intuition to a new information we need about pages.
When a random surfer is at $q$, it will walk randomly from $q$ and will eventually zap to a random page (which might be $p$ with probability $1/n$).
Before zapping, this random surfer might already pass through $p$.
We can define $z_{pq}$ as the expected number of times that a random surfer starting at $q$ pass through $p$ (counted $q$ if $q=p$) before zapping.
$p$ should rather have outlinks to pages $q$ that have high $z_{pq}$.

It is therefore not so surprising to discover that $z_{pq}$ is actually $e_p^T(I-\beta P)^{-1}e_q$.
\cite{avrachenkov2006effect} discovers all that and concludes by giving the optimal outlink strategy for a webpage which is having only one outlink pointing to $q^* = \argmax_{p \neq q} z_{pq}$.
Of course, the best strategy is to only have a self loop but that would mean that $p$ is a spider trap which can be detected.
If the search engine allows self-loop the optimal strategy is to have 2 links, a self-loop and a link to $q^*$.

\section{Choice of inlinks (aka backlinks)}
A first question might be to try to optimize the PageRank of a page
by adding $k$ new link.

\cite{olsen2010maximizing} shows that this problem has no fully polynomial time scheme (FPTAS) if $P \neq NP$ and also show that it is W[1]-hard.

\cite{olsen2010constant} compares the naïve algorithm for this problem and a $r$-Greedy algorithm he develops.
He shows that the naïve algorithm does not perform very well and he shows a lower bound for the pagerank of its page which is a constant times the best pagerank possible. It is
\[ \pi_p^G \geq \pi_p^o(1 - \beta^2)(1 - 1/e) \]
where $p$ is the page for which we try to maximize the PageRank,
$\pi_p^G$ is the PageRank obtained by its $r$-Greedy algorithm, $\pi_p^o$ is the best PageRank that could be optained, $\beta$ is therelaxation factor and $e$ is the neperian constant.
For the usual value $\beta = 0.85$, this constant is approximatively $0.175$ which may seems not that good but is not terrible either.

\subsection{Best link structure for a set of pages}
The best link structure has already been discussed for a single node.
\cite{de2008maximizing} analyses the link structure of the pages in $P$ that maximizes the sum of their PageRanks.
\todo[inline]{Describe it}

If we want to us this structure in practice a problem remains.
We do not know in which order the pages need to be in the chain
nor what is the sinking page (even if we know that is a parent of $P$).

There is a conjecture at the end of \cite{de2008maximizing}.
Instead of simply proving the conjecture, we will prove a generalization.
\begin{mytheo}[Partition of the chain]
  Let $P_1,P_2 \subseteq P$ be a partition of $P$ such that
  $i \in P_1$ if $i$ has an in-link from $\bar{P}$ and $i \in P_2$
  otherwise.
  If $z_i = z_j$ for all $i,j \in P$,
  then with the optimal link structure,
  $v_i > v_j$ for all $(i,j) \in P_1 \times P_2$.
  In other words, in the chain there is first all pages of
  $P_1$ then all pages of $P_2$.
  \begin{proof}
    Let's suppose that their is $(i,j) \in P_1 \times P_2$
    such that $v_i < v_j$ ($v_i = v_j$ is impossible (see \cite[theorem~12]{de2008maximizing}).

    Then since $z_i = z_j$, we can simulate the situation of swapping $i$ and $j$ in the chain
    by giving the inlinks of $i$ to $j$.
    Using \cite[theorem~5]{de2008maximizing}, we see that we increase the PageRank each time we give one of the inlinks since
    we have each time
    \[ \delta^Tv = \frac{v_j - v_i}{d} > 0 \]
    where $d$ is the out-degree of the parent of $i$ for which we change de destination of the link.
  \end{proof}
\end{mytheo}

\cite{de2008maximizing} says
``If this conjecture was true we could also ask if the node $j \in I$ such that
$(j, i) \in E_{in(P)}$ where $i \in \argmax_k v_k$ belongs to $V$.
Sadly, this is not so simple. \todo{find a counter example}
As we will see, the first page of the forward chain could be there not
because it has a parent in $V$ but because it has many parents with high $v$ even if they are not in $V$.

\subsection{Optimal order with no leak}
\label{sec:no_leak}
Let's now have a prelude, showing how we could easily choose the order of the pages in the chain if there were
no leaking page.
In that case of course it would be a spider web and the optimal linkage strategy wouldn't be a chain but this derivation is similar
to the one with a leaking page and helps understand it.

We now try to find the relation between the graph with the forward chain and the basic absorbing graph.
Let $v^{0_i}$ be the usual $v$ for the basic absorbing graph if the node $i$,
i.e. $v^{0_i} = (I - cP)e_i$ where the $i$th line of $P$ is $e_i^T$.
In order to do that, we will introduce $p_{ijk}$ which is the probability that a random walker starting at $j$
will arrive at $i$ after following $k$ links before zapping.
We have naturally $p_{iik} = c^k$ since the only out-link of $i$ leads to $i$ in its basic absorbing graph.
Therefore
\[ v_i^{0_i} = \sum_{k=0}^\infty c^k = \lim_{k \to \infty} \frac{1-c^k}{1-c} = \frac{1}{1-c}. \]
For $j \neq i$, we can reuse the value $v_i^{0_i}$ we have just found one we arrive at $i$.
\[ v_j^{0_i} = \sum_{k=0}^\infty p_{ijk} v_i^{0_i} = \frac{1}{1-c} \sum_{k=0}^\infty p_{ijk}. \]

For our forward chain,
once we arrive at a page $i \in P$, we use $v_i$.
So for $j \in \bar{P}$
\begin{align*}
  v_j & = \sum_{i \in P} \sum_{k = 0}^\infty p_{ijk} v_i\\
      & = \sum_{i \in P} v_i \sum_{k = 0}^\infty p_{ijk}\\
      & = \sum_{i \in P} v_i (1-c) v_j^{0_i}
\end{align*}
and therefore
\begin{align*}
  \sum_{i \in P} v_i + \sum_{j \in \bar{P}}
  & = \sum_{i \in P} v_i + \sum_{j \in \bar{P}} \sum_{i \in P} v_i (1-c) v_j^{0_i}\\
  & = \sum_{i \in P} v_i + \sum_{i \in P} v_i \sum_{j \in \bar{P}} (1-c) v_j^{0_i}\\
  & = \sum_{i \in P} v_i \left(1 + \sum_{j \in \bar{P}} (1-c) v_j^{0_i}\right)\\
  & = w^T v_P
\end{align*}
where $w$ is defined as expected.
We know from \cite{de2008maximizing} that the order of $v_i$ (which is strict) is the same that
the order of the pages in the chain, i.e.
\[ v_{n_P} < v_{n_P-1} < \cdots < v_2 < v_1 \]
where $1$ is the leaking page, $v_2$ is the page before it, ...

Choosing the order maximizing this scalar product is trivial using the ``Rearrangement inequality''.
The order of $w$ gives us therefore immediately the order of our pages in the forward chain.
We can obtain $w$ solving the $n_P$ system $(I - cP^{0_i})v^{0_i} = e_i$.
This is far better than running $n_P!$ times PageRank.

\subsection{Optimal order}
Let $l$ be the leak, i.e. $(1,l) \in E$ and $l \in \bar{P}$.
Wlog, let $l = n_{P}+1$.
Let $P_P$ be the part of $P$ with only the pages $1, \ldots, n_P$.
In section~\ref{sec:no_leak},
\[ (I - cP)v = e_P \]
implied that
\[ (I - cP_P)v_P = \1 \]
since
\[ P =
  \begin{pmatrix}
    P_P & 0\\
    * & *
  \end{pmatrix}.
\]
where
\[
  P_P =
  \begin{pmatrix}
    (n+1)^{-1} & (n+1)^{-1} & \cdots & (n+1)^{-1} & (n+1)^{-1}\\
    n^{-1} & n^{-1} & \cdots & n^{-1} & n^{-1}\\
           & (n-1)^{-1} & \cdots & (n-1)^{-1} & (n-1)^{-1}\\
           & & \ddots & \vdots & \vdots\\
    & & & 1/2 & 1/2
  \end{pmatrix}
\]

Now, the $n_P$ first lines of $P$ are
\[
  \begin{pmatrix}
    (n+1)^{-1} & (n+1)^{-1} & \cdots & (n+1)^{-1} & (n+1)^{-1} & 1 & 0 & \cdots & 0\\
    n^{-1} & n^{-1} & \cdots & n^{-1} & n^{-1} & 0 & 0 & \cdots & 0\\
           & (n-1)^{-1} & \cdots & (n-1)^{-1} & (n-1)^{-1} & 0 & 0 & \cdots & 0\\
           & & \ddots & \vdots & \vdots & \vdots & \vdots & & \vdots \\
           & & & 1/2 & 1/2 & 0 & 0 & \cdots & 0
  \end{pmatrix}.
\]
and therefore
\[ (I - cP_P)v_P = \1 + c e_1 v_l. \]

But we know that
\[ v_l = (1-c) \sum_{i \in P} v_i v_l^{0_i}. \]
Noting
\[ v_l^0 =
  \begin{pmatrix}
    v_l^{0_1} \\ v_l^{0_2} \\ \vdots \\ v_l^{0_{n_P}}
  \end{pmatrix}
\]
we have
\[ v_l = (1-c) {v_l^0}^T v_P \]
and consequently
\[ (I - cP_P)v_P = \1 + c (1-c) e_1 {v_l^0}^T v_P \]
or
\[ (I - cP_P - c (1-c) e_1 {v_l^0}^T)v_P = \1. \]

Using Sherman-Morrison, we have
\begin{align*}
  (I - cP_P - c (1-c) e_1 {v_l^0}^T)^{-1} & = (I - cP_P)^{-1} + (I - cP_P)^{-1}e_1 c(1-c) \frac{{v_l^0}^T(I-cP_P)^{-1}}{1 - c(1-c){v_l^0}^T(I-cP)^{-1}e_1}\\
  (I - cP_P - c (1-c) e_1 {v_l^0}^T)^{-1}\1 & = h + g c(1-c) \frac{{v_l^0}^Th}{1 - c(1-c){v_l^0}^Tg}
\end{align*}
defining $h,g$ appropriatelly.

We now have to maximize
\[ w^T \left(h + g c(1-c) \frac{{v_l^0}^Th}{1 - c(1-c){v_l^0}^Tg}\right) \]
where $h$ and $g$ can be precomputed.
The only problem is that we have to choose the permutation $\sigma$ that we apply to $w$ and $v_l^0$ (the same !).
For $v_l^0$, if there is 0 elements, we can have less than $n_P!$ (and the order of the others is trivial to find with rearrangement like before).
In the worst case we still have $n_P!$ but we do not have to compute the pagerank each time but only evaluating this expression which is $\bigoh(n_P)$ !

More generally, since $g$ and $h$ are in the same order \todo{prove it} and because we should maximize both ${v_l^0}^Tg$ and ${v_l^0}^Th$ to have the maximum expression (since $1 > c(1-c){v_l^0}^Tg$\todo{prove it}),
if there is $i_1, i_2$ for which $w_{i_1}, w_{i_2}$ are in the same order than ${v_l^0}_{i_1}, {v_l^0}_{i_2}$,
we can deduce the order of $i_1, i_2$ in $g$ and $h$ so in practice we will be able to do a lot better than $n_P!$ using this trick too.

\section{Adding external links}
In the case where we can add a link in a webpage, such as a forum or any other accessible page, we include the webpage in the controlled set $\mathcal{P}$.\\
Intuitively, doing so should result in a pagerank rise of the target set, although it is not always the case.
%TODO : example
If the target set is a singleton, adding a link towards this singleton does increase its pagerank. But is it the optimal strategy?\\
When two pages $i$ and $j$ have similar expected number of steps before zapping $v_i$ and $v_j$, we can guess that adding a link from the page with the highest pagerank should yield a better result. How can we prove it? 

\subsection{}

\section{Incomplete information and approximation of z}
In order to be able to apply those results in the real world, we need to be able to compute the inverse matrix $(I-cP)e_{\mathcal{P}}$. However, this is not such an easy thing to do, given the actual computational power and storage needed. In this section we will partition the set of nodes, $V$ in two sets $\mathcal{L}_1$ and $\mathcal{L}_2$. We are here only interested in the elements $z_{ij}$ of $(I-cP)$ so that $i,j \in \mathcal{L}_1$. \\
We define $\tilde{P} = \begin{pmatrix}\tilde{P}_1 & 0 \\
0 & \tilde{P}_2 \end{pmatrix}
$
We can see that the matrix $\tilde{P}_1$ is easier to obtain than the whole matrix $P$.
We can here use Woodbury in order to link $P$ and $\tilde{P}$
\begin{eqnarray*}
I-cP & = & I-c\tilde{P} + c(\tilde{P}-P) \\
(I-cP)^{-1} & = & (I-c\tilde{P})^{-1} + (I-c\tilde{P})^{-1}cU(I-V(I-c\tilde{P})^{-1}cU)^{-1}V(I-c\tilde{P})^{-1}
\end{eqnarray*}
where $UV = (\tilde{P}-P)$ 
\subsection{Case 1 : only one node in each set links to the other set}
Suppose the two sets $\mathcal{L}_1$ and $\mathcal{L}_2$ are linked by two nodes $l\in \mathcal{L}_1$ and $m \in \mathcal{L}_2$ which point to each other
$$U = \begin{pmatrix}
e_{l}  & e_{m} \end{pmatrix}$$
$$V = \begin{pmatrix}
\frac{1}{d_{l}(d_{l}-1)} & \hdots & \frac{1}{d_{l}(d_{l}-1)} & \frac{1}{d_{l}(d_{l}-1)} & -\frac{1}{d_l} & 0 & \hdots & 0 \\
0 &\hdots & 0 & -\frac{1}{d_m} & \frac{1}{d_{m}(d_{m}-1)} & \frac{1}{d_{m}(d_{m}-1)} & \hdots & \frac{1}{d_{m}(d_{m}-1)}\end{pmatrix}$$

On pose $A = c(I-c\tilde{P})^{-1}U$
$$ A = \begin{pmatrix}
z_{:l} & z_{:m} 
\end{pmatrix}$$
$$VA = $$
%Assumption : $\forall i,j \in \mathcal{L}_1, k \in \mathcal{L}_2 \: z_{ij} > z_{ik}$\\
 


\bibliographystyle{plain}
\bibliography{biblio}

\end{document}
