\documentclass{article}

\usepackage[utf8x]{inputenc}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{fullpage}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{todonotes}

% Math symbols
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}

% Numbers and units
\usepackage{siunitx}

\DeclareMathOperator{\newdiff}{d} % use \dif instead
\newcommand{\dif}{\newdiff\!}
\newcommand{\fpart}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\ffpart}[2]{\frac{\partial^2 #1}{\partial #2^2}}
\newcommand{\fdpart}[3]{\frac{\partial^2 #1}{\partial #2\partial #3}}
\newcommand{\fdif}[2]{\frac{\dif #1}{\dif #2}}
\newcommand{\ffdif}[2]{\frac{\dif^2 #1}{\dif #2^2}}
\newcommand{\constant}{\ensuremath{\mathrm{cst}}}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\newcommand{\1}{\mathbf{1}}

% Theorem and definitions
\theoremstyle{definition}
\newtheorem{mydef}{Définition}
\newtheorem{mynota}[mydef]{Notation}
\newtheorem{myprop}[mydef]{Propriétés}
\newtheorem{myrem}[mydef]{Remarque}
\newtheorem{myform}[mydef]{Formules}
\newtheorem{mycorr}[mydef]{Corrolaire}
\newtheorem{mytheo}[mydef]{Théorème}
\newtheorem{mylem}[mydef]{Lemme}
\newtheorem{myexem}[mydef]{Exemple}
\newtheorem{myineg}[mydef]{Inégalité}



\author{Benoît Legat}
\title{PageRank optimization}

\begin{document}

\maketitle

\section{Reminder}
We will adopt the transposed notation due to the fact that all papers do so.

So
\[ \pi_{k+1}^T = \pi_k^T cP + t^T(1-c) \]
or
\[ \pi_{k+1}^T = \pi_k^T (cP + \1 t^T(1-c)) \]
and at the convergence
\[ \pi^T = \pi^T (cP + \1 t^T(1-c)) \]
so
\[ \pi^T = (1-c)\1 t^T(I - cP)^{-1} \]
where $(1 - cP)^{-1} \triangleq Z$ as we will see later.

\section{The effect of adding links}
\cite{avrachenkov2004decomposition} show that adding a link
from $i$ to $j$ always increase the PageRank of $j$.
The worst case for a page is having no inlinks which gives a PageRank of $(1-c)/n$.

It analyses the decomposition of the web in communities,
set of pages that does not link to each other (because they are of a difference subject for example).
This is excellent for parallelizing the computation of PageRank.
He then proves that a community has no interest in adding link to another community,
in will decrease its PageRank.

This is an example that show that adding an outlink for a page $p$ can decrease the PageRank of $p$.
However, it can also increase the PageRank of a page.
Consider for example the case where $p$ links to a page of another community.
Adding a link from $p$ to a page that links to $p$ can decrease the number of random surfers that go to this other community and increase the PageRank of $p$.

This gives the intuition to a new information we need about pages.
When a random surfer is at $q$, it will walk randomly from $q$ and will eventually zap to a random page (which might be $p$ with probability $1/n$).
Before zapping, this random surfer might already pass through $p$.
We can define $z_{pq}$ as the expected number of times that a random surfer starting at $q$ pass through $p$ (counted $q$ if $q=p$) before zapping.
$p$ should rather have outlinks to pages $q$ that have high $z_{pq}$.

It is therefore not so surprising to discover that $z_{pq}$ is actually $e_p^T(I-\beta P)^{-1}e_q$.
\cite{avrachenkov2006effect} discovers all that and concludes by giving the optimal outlink strategy for a webpage which is having only one outlink pointing to $q^* = \argmax_{p \neq q} z_{pq}$.
Of course, the best strategy is to only have a self loop but that would mean that $p$ is a spider trap which can be detected.
If the search engine allows self-loop the optimal strategy is to have 2 links, a self-loop and a link to $q^*$.

\section{Choice of inlinks (aka backlinks)}
A first question might be to try to optimize the PageRank of a page
by adding $k$ new link.

\cite{olsen2010maximizing} shows that this problem has no fully polynomial time scheme (FPTAS) if $P \neq NP$ and also show that it is W[1]-hard.

\cite{olsen2010constant} compares the naïve algorithm for this problem and a $r$-Greedy algorithm he develops.
He shows that the naïve algorithm does not perform very well and he shows a lower bound for the pagerank of its page which is a constant times the best pagerank possible. It is
\[ \pi_p^G \geq \pi_p^o(1 - \beta^2)(1 - 1/e) \]
where $p$ is the page for which we try to maximize the PageRank,
$\pi_p^G$ is the PageRank obtained by its $r$-Greedy algorithm, $\pi_p^o$ is the best PageRank that could be optained, $\beta$ is therelaxation factor and $e$ is the neperian constant.
For the usual value $\beta = 0.85$, this constant is approximatively $0.175$ which may seems not that good but is not terrible either.

\subsection{Best link structure for a set of pages}
The best link structure has already been discussed for a single node.
\cite{de2008maximizing} analyses the link structure of the pages in $P$ that maximizes the sum of their PageRanks.
\todo[inline]{Describe it}

If we want to us this structure in practice a problem remains.
We do not know in which order the pages need to be in the chain
nor what is the sinking page (even if we know that is a parent of $P$).

There is a conjecture at the end of \cite{de2008maximizing}.
Instead of simply proving the conjecture, we will prove a generalization.
\begin{mytheo}[Partition of the chain]
  Let $P_1,P_2 \subseteq P$ be a partition of $P$ such that
  $i \in P_1$ if $i$ has an in-link from $\bar{P}$ and $i \in P_2$
  otherwise.
  If $z_i = z_j$ for all $i,j \in P$,
  then with the optimal link structure,
  $v_i > v_j$ for all $(i,j) \in P_1 \times P_2$.
  In other words, in the chain there is first all pages of
  $P_1$ then all pages of $P_2$.
  \begin{proof}
    Let's suppose that their is $(i,j) \in P_1 \times P_2$
    such that $v_i < v_j$ ($v_i = v_j$ is impossible (see \cite[theorem~12]{de2008maximizing}).

    Then since $z_i = z_j$, we can simulate the situation of swapping $i$ and $j$ in the chain
    by giving the inlinks of $i$ to $j$.
    Using \cite[theorem~5]{de2008maximizing}, we see that we increase the PageRank each time we give one of the inlinks since
    we have each time
    \[ \delta^Tv = \frac{v_j - v_i}{d} > 0 \]
    where $d$ is the out-degree of the parent of $i$ for which we change de destination of the link.
  \end{proof}
\end{mytheo}

\cite{de2008maximizing} says
``If this conjecture was true we could also ask if the node $j \in I$ such that
$(j, i) \in E_{in(P)}$ where $i \in \argmax_k v_k$ belongs to $V$.
Sadly, this is not so simple. \todo{find a counter example}
As we will see, the first page of the forward chain could be there not
because it has a parent in $V$ but because it has many parents with high $v$ even if they are not in $V$.

Let's now have a prelude, showing how we could easily choose the order of the pages in the chain if there were
no leaking page.
In that case of course it would be a spider web and the optimal linkage strategy wouldn't be a chain but this derivation is similar
to the one with a leaking page and helps understand it.

We now try to find the relation between the graph with the forward chain and the basic absorbing graph.
Let $v^{0_i}$ be the usual $v$ for the basic absorbing graph if the node $i$,
i.e. $v^{0_i} = (I - cP)e_i$ where the $i$th line of $P$ is $e_i^T$.
In order to do that, we will introduce $p_{ijk}$ which is the probability that a random walker starting at $j$
will arrive at $i$ after following $k$ links before zapping.
We have naturally $p_{iik} = c^k$ since the only out-link of $i$ leads to $i$ in its basic absorbing graph.
Therefore
\[ v_i^{0_i} = \sum_{k=0}^\infty c^k = \lim_{k \to \infty} \frac{1-c^k}{1-c} = \frac{1}{1-c}. \]
For $j \neq i$, we can reuse the value $v_i^{0_i}$ we have just found one we arrive at $i$.
\[ v_j^{0_i} = \sum_{k=0}^\infty p_{ijk} v_i^{0_i} = \frac{1}{1-c} \sum_{k=0}^\infty p_{ijk}. \]

For our forward chain,
once we arrive at a page $i \in P$, we use $v_i$.
So for $j \in \bar{P}$
\begin{align*}
  v_j & = \sum_{i \in P} \sum_{k = 0}^\infty p_{ijk} v_i\\
      & = \sum_{i \in P} v_i \sum_{k = 0}^\infty p_{ijk}\\
      & = \sum_{i \in P} v_i (1-c) v_j^{0_i}
\end{align*}
and therefore
\begin{align*}
  \sum_{i \in P} v_i + \sum_{j \in \bar{P}}
  & = \sum_{i \in P} v_i + \sum_{j \in \bar{P}} \sum_{i \in P} v_i (1-c) v_j^{0_i}\\
  & = \sum_{i \in P} v_i + \sum_{i \in P} v_i \sum_{j \in \bar{P}} (1-c) v_j^{0_i}\\
  & = \sum_{i \in P} v_i \left(1 + \sum_{j \in \bar{P}} (1-c) v_j^{0_i}\right)\\
  & = w^T v_P
\end{align*}
where $w$ is defined as expected.
Maximizing this scalar product is trivial using the ``Rearrangement inequality''.
The order of $w$ gives us therefore immediately the order of our pages in the forward chain.

\todo[inline]{J'écris le reste demain matin}

\bibliographystyle{plain}
\bibliography{biblio}

\end{document}
